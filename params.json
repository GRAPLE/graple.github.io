{
  "name": "GRAPLE",
  "tagline": "Distributed computing made easy for lake ecology modeling",
  "body": "### Welcome to GRAPLEr.\r\nGRAPLEr is an R-based open-source software product of GRAPLE, the [GLEON](http://www.gleon.org/) Research and [PRAGMA](http://www.pragma-grid.net/) Lake Expedition.\r\n\r\nGRAPLEr brings the power of distributed computing to the fingertips of lake ecology modelers. While it is relatively easy to run one lake model simulation on a personal computer, it is more difficult to execute multiple simulations, which requires additional computing and human resources. To overcome this problem, GRAPLEr, a distributed computing system, integrates and applies overlay virtual network, high-throughput computing, and Web service technologies. GRAPLEr allows submission of hundreds or thousands of General Lake Model (GLM) simulations, runs these lake model simulations efficiently, and retrieves model output.\r\n\r\n### Using GRAPLEr\r\n\r\nGRAPLEr, available on GitHub, is installed on a personal computer and integrated into the R development environment. It acts as a proxy to translate user commands written in R into Web service calls and arranges data between the client and Web service. A GLM simulation is specified by a set of input files (csv files) and model parameters (nml file). The required input files consist of time-series meteorological and inflow data. An additional outflow csv file can be included. Based on inputs, GRAPLEr either (A) performs a batch job which submits multiple preconfigured simulations as a job or (B1) performs a linear sweep or (B2) random sweep which generates multiple simulation input files, as specified, for submission:\r\n\r\n<p><img src=\"Slide1.jpg\" align=\"left\" height=\"432\" width=\"576\" ></p>\r\n\r\nThe batch job or option A requires multiple simulation folders with required meteorological, inflow, and parameter files:\r\n\r\n![](Slide2.jpg =576x432)\r\n\r\nThe linear or random sweep jobs B require a single set of baseline meteorological, inflow, and parameter files and a job description file (csv file) specifying constant or random distribution offsets to input variables within the meteorological and inflow files:\r\n\r\n![](Slide3.jpg =576x432)\r\n\r\n![](Slide4.jpg =576x432)\r\n \r\nThe job description file specifies the file (met.csv or inflow.csv) to be modified, number of samples or iterations, variables, mathematical operation (add, sub, mult, or div), type of distribution (linear, random, uniform, binomial, or Poisson), and range of values. Next, GRAPLEr configures, queues, and runs jobs and consolidates and prepares results for download. The resulting output at the completion of the model run is a netCDF file containing time-series data of lake variables at varying depths.\r\n\r\n\r\n### Getting started\r\n\r\nYou can go through the [project EDDIE](http://cemast.illinoisstate.edu/data-for-students/modules/lake-modeling.shtml) module to test-drive the execution of hundreds of GLM model runs through GRAPLEr\r\n\r\n### Contact us\r\n\r\nFor additional information, contact Renato Figueiredo (renato at acis.ufl.edu), Cayelan Carey (cayelan at vt.edu) or Paul Hanson (pchanson at wisc.edu)\r\n\r\n### Acknowledgments\r\n\r\nGRAPLEr has been developed as a collaboration between researchers in PRAGMA and GLEON, with support from a supplement the the PRAGMA award (NSF OCI-1234983).",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}